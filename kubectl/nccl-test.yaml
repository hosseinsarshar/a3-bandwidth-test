apiVersion: v1
kind: Service
metadata:
  name:  nccl-host-1
spec:
  selector:
    name:  nccl-host-1
  clusterIP: None
---

apiVersion: v1
kind: Service
metadata:
  name: nccl-host-2
spec:
  selector:
    name: nccl-host-2
  clusterIP: None
---
apiVersion: v1
kind: Pod
metadata:
  name: nccl-test-host-1
  labels:
    name: nccl-host-1
spec:
  hostname: host1
  subdomain: nccl-host-1
  hostNetwork: true
  dnsPolicy: ClusterFirstWithHostNet
  containers:
    - name: tcpxo-daemon
      image: us-docker.pkg.dev/gce-ai-infra/gpudirect-tcpxo/tcpgpudmarxd-dev:v1.0.8
      imagePullPolicy: Always
      command: ["/bin/sh", "-c"]
      args:
        - |
          set -ex
          chmod 755 /fts/entrypoint_rxdm_container.sh
          /fts/entrypoint_rxdm_container.sh --num_hops=2 --num_nics=8 --uid= --alsologtostderr
      securityContext:
        privileged: true
      volumeMounts:
        - name: nvidia-install-dir-host
          mountPath: /usr/local/nvidia
      env:
        - name: LD_LIBRARY_PATH
          value: /usr/local/nvidia/lib64
    - name: nccl-test
      image: determinedai/environments:cuda-11.8-pytorch-2.0-gpu-0.31.1
      imagePullPolicy: Always
      command: ["sh", "-c"] # Use sh to execute multiple commands
      args: 
        - |
          python -c "print('******* All Reduce Network Benchmark Starts *******')"
          rm -f /usr/share/all_reduce_benchmarks/workload_terminated
          python -c "print('Number of nodes participating: {{ $node_count }}')"
          echo Master address: $MASTER_ADDR
          git clone https://github.com/stas00/ml-engineering.git
          python -u -m torch.distributed.run \
            --nproc_per_node 8 \
            --nnodes {{ $node_count }} \
            --rdzv_endpoint nccl-host-2:6000 \
            --rdzv_backend c10d \
            --max_restarts 0 \
            --role `hostname -s`: \
            --tee 3 \
            ml-engineering/network/benchmarks/all_reduce_bench.py
          python -c "print('******* All Reduce Network Benchmark Completed *******')"
          while true; do echo 'Running'; sleep 60; done"
      env:
        - name: LD_LIBRARY_PATH
          value: /usr/local/nvidia/lib64
      securityContext:
        privileged: true
      volumeMounts:
        - name: nvidia-install-dir-host
          mountPath: /usr/local/nvidia
        - name: shared-memory
          mountPath: /dev/shm
      resources:
        limits:
          nvidia.com/gpu: 8
  volumes:
    - name: nvidia-install-dir-host
      hostPath:
        path: /home/kubernetes/bin/nvidia
    - name: shared-memory
      emptyDir:
        medium: "Memory"
        sizeLimit: 1Gi

---
apiVersion: v1
kind: Pod
metadata:
  name: nccl-test-host-2
  labels:
    name: nccl-host-2
spec:
  hostname: host2
  subdomain: nccl-host-2
  hostNetwork: true
  dnsPolicy: ClusterFirstWithHostNet
  containers:
    - name: tcpxo-daemon
      image: us-docker.pkg.dev/gce-ai-infra/gpudirect-tcpxo/tcpgpudmarxd-dev:v1.0.8
      imagePullPolicy: Always
      command: ["/bin/sh", "-c"]
      args:
        - |
          set -ex
          chmod 755 /fts/entrypoint_rxdm_container.sh
          /fts/entrypoint_rxdm_container.sh --num_hops=2 --num_nics=8 --uid= --alsologtostderr
      securityContext:
        privileged: true
      volumeMounts:
        - name: nvidia-install-dir-host
          mountPath: /usr/local/nvidia
      env:
        - name: LD_LIBRARY_PATH
          value: /usr/local/nvidia/lib64
    - name: nccl-test
      image: determinedai/environments:cuda-11.8-pytorch-2.0-gpu-0.31.1
      imagePullPolicy: Always
      command: ["sh", "-c"] # Use sh to execute multiple commands
      args: 
        - |
          python -c "print('******* All Reduce Network Benchmark Starts *******')"
          rm -f /usr/share/all_reduce_benchmarks/workload_terminated
          python -c "print('Number of nodes participating: {{ $node_count }}')"
          echo Master address: $MASTER_ADDR
          git clone https://github.com/stas00/ml-engineering.git
          python -u -m torch.distributed.run \
            --nproc_per_node 8 \
            --nnodes {{ $node_count }} \
            --rdzv_endpoint nccl-host-2:6000 \
            --rdzv_backend c10d \
            --max_restarts 0 \
            --role `hostname -s`: \
            --tee 3 \
            ml-engineering/network/benchmarks/all_reduce_bench.py
          python -c "print('******* All Reduce Network Benchmark Completed *******')"
          while true; do echo 'Running'; sleep 60; done"
      env:
        - name: LD_LIBRARY_PATH
          value: /usr/local/nvidia/lib64
      securityContext:
        privileged: true
      volumeMounts:
        - name: shared-memory
          mountPath: /dev/shm
      resources:
        limits:
          nvidia.com/gpu: 8
  volumes:
    - name: nvidia-install-dir-host
      hostPath:
        path: /home/kubernetes/bin/nvidia
    - name: shared-memory
      emptyDir:
        medium: "Memory"
        sizeLimit: 1Gi